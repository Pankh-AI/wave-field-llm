{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V4.3.4 Component Ablation Benchmark\n",
    "\n",
    "**SPECTRE-Wave Field LLM** — Isolating the impact of each V4.3.4 fix:\n",
    "- A) NormalizedExp activation (was ELU+1)\n",
    "- B) SpectralGate init 10x stronger (0.1 vs 0.01)\n",
    "- C) Kernel damping range expanded (-3.0 vs -1.4)\n",
    "\n",
    "**Crash-safe**: All results saved to Google Drive. If Colab disconnects, just re-run all cells — completed variants are skipped automatically.\n",
    "\n",
    "**Estimated time**: ~5hrs on T4 (6 variants x ~50min each)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mount_drive"
   },
   "source": [
    "# Cell 1: Mount Google Drive (persistence layer)\n",
    "# All results, checkpoints, cache, and monitor data persist here\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "DRIVE_DIR = '/content/drive/MyDrive/wavellm_results'\n",
    "os.makedirs(DRIVE_DIR, exist_ok=True)\n",
    "os.makedirs(f'{DRIVE_DIR}/cache', exist_ok=True)\n",
    "os.makedirs(f'{DRIVE_DIR}/monitor', exist_ok=True)\n",
    "print(f'Drive dir: {DRIVE_DIR}')\n",
    "print(f'Contents: {os.listdir(DRIVE_DIR)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "setup_repo"
   },
   "source": [
    "# Cell 2: Clone repo + install deps (idempotent — safe to re-run)\n",
    "import os\n",
    "REPO_DIR = '/content/wave-field-llm'\n",
    "DRIVE_DIR = '/content/drive/MyDrive/wavellm_results'\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/Pankh-AI/wave-field-llm.git {REPO_DIR}\n",
    "else:\n",
    "    !cd {REPO_DIR} && git pull --ff-only\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "!pip install -q torch datasets tokenizers tqdm\n",
    "\n",
    "# CRITICAL: Symlink results/ -> Google Drive\n",
    "# This makes ALL checkpoints, cache, and results auto-persist to Drive\n",
    "results_link = os.path.join(REPO_DIR, 'results')\n",
    "if os.path.islink(results_link):\n",
    "    os.unlink(results_link)\n",
    "elif os.path.isdir(results_link):\n",
    "    import shutil\n",
    "    shutil.rmtree(results_link)\n",
    "os.symlink(DRIVE_DIR, results_link)\n",
    "\n",
    "# Verify symlink\n",
    "assert os.path.islink(results_link), 'Symlink failed!'\n",
    "assert os.path.realpath(results_link) == DRIVE_DIR, 'Symlink points to wrong dir!'\n",
    "print(f'results/ -> {DRIVE_DIR} (symlinked to Drive)')\n",
    "print(f'Cache contents: {os.listdir(os.path.join(DRIVE_DIR, \"cache\"))}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "verify_gpu"
   },
   "source": [
    "# Cell 3: Verify GPU + show resume state\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "DRIVE_DIR = '/content/drive/MyDrive/wavellm_results'\n",
    "\n",
    "# GPU check\n",
    "assert torch.cuda.is_available(), 'No GPU! Go to Runtime > Change runtime type > T4 GPU'\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "print(f'GPU: {gpu_name} ({vram_gb:.1f} GB VRAM)')\n",
    "\n",
    "# AMP dtype selection\n",
    "if 'T4' in gpu_name or 'V100' in gpu_name:\n",
    "    print(f'AMP: fp16 + GradScaler (narrow exponent range)')\n",
    "elif 'A100' in gpu_name or 'H100' in gpu_name:\n",
    "    print(f'AMP: bf16, no GradScaler needed')\n",
    "\n",
    "# Resume state check\n",
    "partial = os.path.join(DRIVE_DIR, 'v434_ablation_partial.json')\n",
    "final = os.path.join(DRIVE_DIR, 'v434_ablation.json')\n",
    "\n",
    "if os.path.exists(final):\n",
    "    with open(final) as f:\n",
    "        data = json.load(f)\n",
    "    print(f'\\nFINAL RESULTS ALREADY EXIST ({len(data[\"results\"])} variants):')\n",
    "    for r in data['results']:\n",
    "        name = r.get('ablation_name', '?')\n",
    "        ppl = r.get('best_ppl', 'N/A')\n",
    "        print(f'  {name}: PPL={ppl}')\n",
    "    print('\\nRe-running Cell 4 will skip all variants (already done).')\n",
    "elif os.path.exists(partial):\n",
    "    with open(partial) as f:\n",
    "        data = json.load(f)\n",
    "    done = data.get('completed_variants', [])\n",
    "    print(f'\\nResuming! {len(done)}/7 variants already done: {done}')\n",
    "    for r in data.get('results', []):\n",
    "        name = r.get('ablation_name', '?')\n",
    "        ppl = r.get('best_ppl', 'N/A')\n",
    "        print(f'  {name}: PPL={ppl}')\n",
    "    print(f'\\nCell 4 will resume from variant {len(done)+1}/7.')\n",
    "else:\n",
    "    print('\\nFresh run - no previous results found on Drive.')\n",
    "    print('Cell 4 will train all 7 variants from scratch (~5hrs on T4).')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "run_ablation"
   },
   "source": [
    "# Cell 4: Run ablation (~5hrs on T4, crash-safe)\n",
    "# - MONITOR=1 (default): WaveFieldMonitor captures physics diagnostics\n",
    "# - Results saved to Drive after EACH variant (crash-safe)\n",
    "# - On reconnect: re-run Cells 1-4, completed variants are skipped\n",
    "!cd /content/wave-field-llm && SEED=42 WANDB=0 python benchmarks/benchmark_v434_ablation.py"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "check_progress"
   },
   "source": [
    "# Cell 5: Check progress (run anytime — even while Cell 4 is running in another tab)\n",
    "import json, os, glob\n",
    "\n",
    "DRIVE_DIR = '/content/drive/MyDrive/wavellm_results'\n",
    "\n",
    "# 1. Check which variants are done\n",
    "partial = os.path.join(DRIVE_DIR, 'v434_ablation_partial.json')\n",
    "final = os.path.join(DRIVE_DIR, 'v434_ablation.json')\n",
    "path = final if os.path.exists(final) else partial\n",
    "\n",
    "if os.path.exists(path):\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    results = data.get('results', [])\n",
    "    status = 'FINAL' if 'v434_ablation.json' in path else 'IN PROGRESS'\n",
    "    print(f'=== {status}: {len(results)} variants done ===')\n",
    "    print(f'{\"Variant\":<30} {\"PPL\":>8} {\"Acc\":>7} {\"tok/s\":>10}')\n",
    "    print(f'{\"-\"*30} {\"-\"*8} {\"-\"*7} {\"-\"*10}')\n",
    "    for r in results:\n",
    "        name = r.get('ablation_name', r.get('run_name', '?'))\n",
    "        ppl = r.get('best_ppl', 'N/A')\n",
    "        acc = r.get('best_acc', 'N/A')\n",
    "        tps = r.get('tokens_per_sec', 'N/A')\n",
    "        ppl_s = f'{ppl:>8.1f}' if isinstance(ppl, (int,float)) else f'{ppl:>8}'\n",
    "        acc_s = f'{acc:>6.1f}%' if isinstance(acc, (int,float)) else f'{acc:>7}'\n",
    "        tps_s = f'{tps:>10,}' if isinstance(tps, (int,float)) else f'{tps:>10}'\n",
    "        print(f'{name:<30} {ppl_s} {acc_s} {tps_s}')\n",
    "else:\n",
    "    print('No results yet - first variant still training.')\n",
    "\n",
    "# 2. Check monitor data for latest/current variant\n",
    "monitor_dirs = sorted(glob.glob(f'{DRIVE_DIR}/monitor/*/'))\n",
    "if monitor_dirs:\n",
    "    latest = monitor_dirs[-1]\n",
    "    name = os.path.basename(latest.rstrip('/'))\n",
    "    steps_file = os.path.join(latest, 'monitor_steps.json')\n",
    "    if os.path.exists(steps_file):\n",
    "        with open(steps_file) as f:\n",
    "            steps = json.load(f)\n",
    "        if steps:\n",
    "            last = steps[-1]\n",
    "            print(f'\\n=== LIVE MONITOR: {name} (step {last.get(\"step\", \"?\")}) ===')\n",
    "            print(f'  Loss: {last.get(\"loss\", \"?\"):.4f}')\n",
    "            print(f'  LR:   {last.get(\"lr\", \"?\"):.6f}')\n",
    "            print(f'  Total steps recorded: {len(steps)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "visualize_monitor"
   },
   "source": [
    "# Cell 6: Visualize physics diagnostics (12-panel dashboard per variant)\n",
    "# Run after each variant completes, or at the end for all variants\n",
    "import glob, os\n",
    "\n",
    "DRIVE_DIR = '/content/drive/MyDrive/wavellm_results'\n",
    "monitor_dirs = sorted(glob.glob(f'{DRIVE_DIR}/monitor/*/'))\n",
    "\n",
    "if not monitor_dirs:\n",
    "    print('No monitor data yet. Run Cell 4 first.')\n",
    "else:\n",
    "    print(f'Found {len(monitor_dirs)} monitored variants:')\n",
    "    for mdir in monitor_dirs:\n",
    "        snap_file = os.path.join(mdir, 'monitor_snapshots.json')\n",
    "        step_file = os.path.join(mdir, 'monitor_steps.json')\n",
    "        if os.path.exists(snap_file):\n",
    "            name = os.path.basename(mdir.rstrip('/'))\n",
    "            print(f'\\n=== Generating dashboard: {name} ===')\n",
    "            cmd = f'python diagnostics/visualize_monitor.py {snap_file}'\n",
    "            if os.path.exists(step_file):\n",
    "                cmd += f' {step_file}'\n",
    "            !{cmd}\n",
    "            # Display dashboard inline\n",
    "            png = snap_file.replace('.json', '_dashboard.png')\n",
    "            if os.path.exists(png):\n",
    "                from IPython.display import Image, display\n",
    "                display(Image(filename=png, width=1200))\n",
    "            else:\n",
    "                print(f'  Dashboard PNG not found at {png}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "final_results"
   },
   "source": [
    "# Cell 7: Final results table + gap analysis\n",
    "import json, os\n",
    "\n",
    "DRIVE_DIR = '/content/drive/MyDrive/wavellm_results'\n",
    "results_path = os.path.join(DRIVE_DIR, 'v434_ablation.json')\n",
    "partial_path = os.path.join(DRIVE_DIR, 'v434_ablation_partial.json')\n",
    "\n",
    "path = results_path if os.path.exists(results_path) else partial_path\n",
    "if not os.path.exists(path):\n",
    "    print('No results found. Run Cell 4 first.')\n",
    "else:\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    results = data['results']\n",
    "    status = 'FINAL' if 'v434_ablation.json' in path else 'PARTIAL'\n",
    "\n",
    "    print(f'{\"=\"*60}')\n",
    "    print(f'  V4.3.4 ABLATION RESULTS ({status})')\n",
    "    print(f'{\"=\"*60}')\n",
    "    print(f'\\n  {\"Variant\":<30} {\"PPL\":>8} {\"Acc\":>7} {\"Params\":>12} {\"tok/s\":>10}')\n",
    "    print(f'  {\"-\"*30} {\"-\"*8} {\"-\"*7} {\"-\"*12} {\"-\"*10}')\n",
    "\n",
    "    std_ppl = None\n",
    "    for r in results:\n",
    "        name = r.get('ablation_name', r.get('run_name', '?'))\n",
    "        ppl = r.get('best_ppl', 'N/A')\n",
    "        acc = r.get('best_acc', 'N/A')\n",
    "        params = r.get('params', 'N/A')\n",
    "        tps = r.get('tokens_per_sec', 'N/A')\n",
    "        ppl_s = f'{ppl:>8.1f}' if isinstance(ppl, (int,float)) else f'{ppl:>8}'\n",
    "        acc_s = f'{acc:>6.1f}%' if isinstance(acc, (int,float)) else f'{acc:>7}'\n",
    "        params_s = f'{params:>12,}' if isinstance(params, (int,float)) else f'{params:>12}'\n",
    "        tps_s = f'{tps:>10,}' if isinstance(tps, (int,float)) else f'{tps:>10}'\n",
    "        print(f'  {name:<30} {ppl_s} {acc_s} {params_s} {tps_s}')\n",
    "        if r.get('ablation') == 'F_standard' and isinstance(ppl, (int,float)):\n",
    "            std_ppl = ppl\n",
    "\n",
    "    # Gap analysis\n",
    "    if std_ppl:\n",
    "        print(f'\\n  --- GAP ANALYSIS (vs Standard PPL {std_ppl:.1f}) ---')\n",
    "        print(f'  {\"Variant\":<30} {\"PPL\":>8} {\"Gap\":>8} {\"Delta\":>8}')\n",
    "        print(f'  {\"-\"*30} {\"-\"*8} {\"-\"*8} {\"-\"*8}')\n",
    "        baseline_ppl = None\n",
    "        for r in results:\n",
    "            ppl = r.get('best_ppl')\n",
    "            if not isinstance(ppl, (int, float)):\n",
    "                continue\n",
    "            name = r.get('ablation_name', r.get('run_name', '?'))\n",
    "            gap = ppl / std_ppl\n",
    "            if r.get('ablation') == 'A_v433_baseline':\n",
    "                baseline_ppl = ppl\n",
    "            delta = f'{((ppl - baseline_ppl) / baseline_ppl * 100):>+7.1f}%' if baseline_ppl else '    base'\n",
    "            print(f'  {name:<30} {ppl:>8.1f} {gap:>7.2f}x {delta}')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}