{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# V4.3.4 Component Ablation Benchmark\n\n**SPECTRE-Wave Field LLM** — Isolating the impact of each V4.3.4 fix:\n- A) NormalizedExp activation (was ELU+1)\n- B) SpectralGate init 10x stronger (0.1 vs 0.01)\n- C) Kernel damping range expanded (-3.0 vs -1.4)\n\n**Crash-safe**: All results saved to Google Drive. If Colab disconnects, just re-run all cells — completed variants are skipped automatically.\n\n**Parallel mode**: 3 processes share the T4 GPU → **~1.5hrs** instead of ~5hrs.\n\n**Estimated time**: ~1.5hrs on T4 (parallel) / ~5hrs (sequential)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mount_drive"
   },
   "source": [
    "# Cell 1: Mount Google Drive (persistence layer)\n",
    "# All results, checkpoints, cache, and monitor data persist here\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "DRIVE_DIR = '/content/drive/MyDrive/wavellm_results'\n",
    "os.makedirs(DRIVE_DIR, exist_ok=True)\n",
    "os.makedirs(f'{DRIVE_DIR}/cache', exist_ok=True)\n",
    "os.makedirs(f'{DRIVE_DIR}/monitor', exist_ok=True)\n",
    "print(f'Drive dir: {DRIVE_DIR}')\n",
    "print(f'Contents: {os.listdir(DRIVE_DIR)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "setup_repo"
   },
   "source": [
    "# Cell 2: Clone repo + install deps (idempotent — safe to re-run)\n",
    "import os\n",
    "REPO_DIR = '/content/wave-field-llm'\n",
    "DRIVE_DIR = '/content/drive/MyDrive/wavellm_results'\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/Pankh-AI/wave-field-llm.git {REPO_DIR}\n",
    "else:\n",
    "    !cd {REPO_DIR} && git pull --ff-only\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "!pip install -q torch datasets tokenizers tqdm\n",
    "\n",
    "# CRITICAL: Symlink results/ -> Google Drive\n",
    "# This makes ALL checkpoints, cache, and results auto-persist to Drive\n",
    "results_link = os.path.join(REPO_DIR, 'results')\n",
    "if os.path.islink(results_link):\n",
    "    os.unlink(results_link)\n",
    "elif os.path.isdir(results_link):\n",
    "    import shutil\n",
    "    shutil.rmtree(results_link)\n",
    "os.symlink(DRIVE_DIR, results_link)\n",
    "\n",
    "# Verify symlink\n",
    "assert os.path.islink(results_link), 'Symlink failed!'\n",
    "assert os.path.realpath(results_link) == DRIVE_DIR, 'Symlink points to wrong dir!'\n",
    "print(f'results/ -> {DRIVE_DIR} (symlinked to Drive)')\n",
    "print(f'Cache contents: {os.listdir(os.path.join(DRIVE_DIR, \"cache\"))}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "verify_gpu"
   },
   "source": "# Cell 3: Verify GPU + show resume state\nimport torch\nimport json\nimport os\nimport glob\n\nDRIVE_DIR = '/content/drive/MyDrive/wavellm_results'\n\n# GPU check\nassert torch.cuda.is_available(), 'No GPU! Go to Runtime > Change runtime type > T4 GPU'\ngpu_name = torch.cuda.get_device_name(0)\nvram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\nprint(f'GPU: {gpu_name} ({vram_gb:.1f} GB VRAM)')\n\n# AMP dtype selection\nif 'T4' in gpu_name or 'V100' in gpu_name:\n    print(f'AMP: fp16 + GradScaler (narrow exponent range)')\nelif 'A100' in gpu_name or 'H100' in gpu_name:\n    print(f'AMP: bf16, no GradScaler needed')\n\n# Resume state check — per-variant files (parallel) + partial JSON (sequential)\nall_variants = ['A_v433_baseline', 'B_normalized_exp_only', 'C_gate_10x_only',\n                'D_kernel_reach_only', 'E_v434_full', 'F_standard']\ndone = set()\n\n# Check per-variant result files\nfor key in all_variants:\n    vpath = os.path.join(DRIVE_DIR, f'v434_ablation_{key}.json')\n    if os.path.exists(vpath):\n        done.add(key)\n\n# Check partial JSON (from sequential runs)\npartial = os.path.join(DRIVE_DIR, 'v434_ablation_partial.json')\nif os.path.exists(partial):\n    with open(partial) as f:\n        data = json.load(f)\n    for r in data.get('results', []):\n        abl = r.get('ablation')\n        if abl:\n            done.add(abl)\n\n# Check final results\nfinal = os.path.join(DRIVE_DIR, 'v434_ablation.json')\nif os.path.exists(final):\n    with open(final) as f:\n        data = json.load(f)\n    for r in data.get('results', []):\n        abl = r.get('ablation')\n        if abl:\n            done.add(abl)\n\nremaining = [v for v in all_variants if v not in done]\n\nif len(done) == len(all_variants):\n    print(f'\\nALL {len(done)} VARIANTS DONE! Run Cell 7 for results.')\nelif done:\n    print(f'\\nResuming: {len(done)}/{len(all_variants)} done, {len(remaining)} remaining')\n    print(f'  Done: {sorted(done)}')\n    print(f'  Remaining: {remaining}')\n    # Show completed results\n    for key in sorted(done):\n        vpath = os.path.join(DRIVE_DIR, f'v434_ablation_{key}.json')\n        if os.path.exists(vpath):\n            with open(vpath) as f:\n                r = json.load(f)\n            ppl = r.get('best_ppl', '?')\n            print(f'    {r.get(\"ablation_name\", key)}: PPL={ppl}')\nelse:\n    print(f'\\nFresh run — no previous results found on Drive.')\n    print(f'Cell 4 will train all {len(all_variants)} variants.')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "run_ablation"
   },
   "source": "# Cell 4: Run ablation — PARALLEL MODE (~1.5hrs on T4)\n# 3 processes share the GPU, each training 2 variants simultaneously.\n# S1 model (22M params) uses ~2GB VRAM, so 3 processes fit easily in 16GB.\n# Each process saves per-variant result files — crash-safe per-variant.\n#\n# To run SEQUENTIAL instead (slower but simpler):\n#   !cd /content/wave-field-llm && SEED=42 WANDB=0 python benchmarks/benchmark_v434_ablation.py\n\nimport subprocess, os, json, glob, time\n\nREPO = '/content/wave-field-llm'\nDRIVE_DIR = '/content/drive/MyDrive/wavellm_results'\n\n# Check what's already done\nall_variants = ['A_v433_baseline', 'B_normalized_exp_only', 'C_gate_10x_only',\n                'D_kernel_reach_only', 'E_v434_full', 'F_standard']\ndone = set()\nfor key in all_variants:\n    vpath = os.path.join(DRIVE_DIR, f'v434_ablation_{key}.json')\n    if os.path.exists(vpath):\n        done.add(key)\n# Also check partial JSON from previous sequential run\npartial = os.path.join(DRIVE_DIR, 'v434_ablation_partial.json')\nif os.path.exists(partial):\n    with open(partial) as f:\n        for r in json.load(f).get('results', []):\n            abl = r.get('ablation')\n            if abl:\n                done.add(abl)\n\nremaining = [v for v in all_variants if v not in done]\n\nif not remaining:\n    print('All 6 variants already done! Run Cell 7 for results.')\nelse:\n    print(f'{len(remaining)} variants remaining: {remaining}')\n    if done:\n        print(f'Skipping (already done): {sorted(done)}')\n\n    # Split remaining into 3 groups for parallel execution\n    n_procs = min(3, len(remaining))\n    groups = [[] for _ in range(n_procs)]\n    for i, v in enumerate(remaining):\n        groups[i % n_procs].append(v)\n    groups = [g for g in groups if g]  # remove empty\n\n    # Launch parallel processes\n    procs = []\n    env = {**os.environ, 'SEED': '42', 'WANDB': '0', 'MONITOR': '1'}\n    for i, group in enumerate(groups):\n        variants_str = ','.join(group)\n        proc_env = {**env, 'VARIANTS': variants_str}\n        log_path = os.path.join(DRIVE_DIR, f'log_proc{i}.txt')\n        print(f'  Process {i}: {variants_str} -> {log_path}')\n        p = subprocess.Popen(\n            ['python', 'benchmarks/benchmark_v434_ablation.py'],\n            cwd=REPO, env=proc_env,\n            stdout=open(log_path, 'w'),\n            stderr=subprocess.STDOUT,\n        )\n        procs.append((i, p, group))\n\n    print(f'\\n{len(procs)} processes launched! Polling every 60s...\\n')\n\n    # Poll for completion with progress updates\n    while any(p.poll() is None for _, p, _ in procs):\n        time.sleep(60)\n        # Count newly done variants\n        now_done = set()\n        for key in all_variants:\n            vpath = os.path.join(DRIVE_DIR, f'v434_ablation_{key}.json')\n            if os.path.exists(vpath):\n                now_done.add(key)\n        new = now_done - done\n        if new:\n            for k in sorted(new):\n                vpath = os.path.join(DRIVE_DIR, f'v434_ablation_{k}.json')\n                try:\n                    with open(vpath) as f:\n                        r = json.load(f)\n                    ppl = r.get('best_ppl', '?')\n                    print(f'  DONE: {r.get(\"ablation_name\", k)} — PPL={ppl}')\n                except:\n                    print(f'  DONE: {k}')\n            done.update(new)\n        running = sum(1 for _, p, _ in procs if p.poll() is None)\n        print(f'  [{time.strftime(\"%H:%M\")}] {len(now_done)}/{len(all_variants)} done, {running} procs running')\n\n    # Final status\n    print(f'\\n{\"=\"*50}')\n    for i, p, group in procs:\n        status = 'OK' if p.returncode == 0 else f'FAIL (code {p.returncode})'\n        print(f'  Process {i} ({\",\".join(group)}): {status}')\n        if p.returncode != 0:\n            log_path = os.path.join(DRIVE_DIR, f'log_proc{i}.txt')\n            print(f'    Check log: {log_path}')\n    print(f'\\nDone! Run Cell 5 to check results, Cell 7 for final table.')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "check_progress"
   },
   "source": "# Cell 5: Check progress (run anytime — even while Cell 4 is running)\nimport json, os, glob\n\nDRIVE_DIR = '/content/drive/MyDrive/wavellm_results'\n\n# 1. Check per-variant result files (parallel mode)\nall_variants = ['A_v433_baseline', 'B_normalized_exp_only', 'C_gate_10x_only',\n                'D_kernel_reach_only', 'E_v434_full', 'F_standard']\nresults = []\ndone = set()\nfor key in all_variants:\n    vpath = os.path.join(DRIVE_DIR, f'v434_ablation_{key}.json')\n    if os.path.exists(vpath):\n        with open(vpath) as f:\n            r = json.load(f)\n        results.append(r)\n        done.add(key)\n\n# Also check partial JSON (sequential mode)\npartial = os.path.join(DRIVE_DIR, 'v434_ablation_partial.json')\nif os.path.exists(partial):\n    with open(partial) as f:\n        data = json.load(f)\n    for r in data.get('results', []):\n        abl = r.get('ablation')\n        if abl and abl not in done:\n            results.append(r)\n            done.add(abl)\n\nremaining = [v for v in all_variants if v not in done]\nprint(f'=== PROGRESS: {len(done)}/{len(all_variants)} variants done ===')\nif remaining:\n    print(f'Remaining: {remaining}')\n\nif results:\n    print(f'\\n{\"Variant\":<30} {\"PPL\":>8} {\"Acc\":>7} {\"tok/s\":>10}')\n    print(f'{\"-\"*30} {\"-\"*8} {\"-\"*7} {\"-\"*10}')\n    for r in results:\n        name = r.get('ablation_name', r.get('run_name', '?'))\n        ppl = r.get('best_ppl', 'N/A')\n        acc = r.get('best_acc', 'N/A')\n        tps = r.get('tokens_per_sec', 'N/A')\n        ppl_s = f'{ppl:>8.1f}' if isinstance(ppl, (int,float)) else f'{ppl:>8}'\n        acc_s = f'{acc:>6.1f}%' if isinstance(acc, (int,float)) else f'{acc:>7}'\n        tps_s = f'{tps:>10,}' if isinstance(tps, (int,float)) else f'{tps:>10}'\n        print(f'{name:<30} {ppl_s} {acc_s} {tps_s}')\n\n# 2. Check process logs (parallel mode)\nfor i in range(3):\n    log_path = os.path.join(DRIVE_DIR, f'log_proc{i}.txt')\n    if os.path.exists(log_path):\n        with open(log_path) as f:\n            lines = f.readlines()\n        if lines:\n            # Show last 5 lines of each log\n            print(f'\\n--- Process {i} log (last 5 lines) ---')\n            for line in lines[-5:]:\n                print(f'  {line.rstrip()}')\n\n# 3. Check monitor data for latest/current variant\nmonitor_dirs = sorted(glob.glob(f'{DRIVE_DIR}/monitor/*/'))\nif monitor_dirs:\n    latest = monitor_dirs[-1]\n    name = os.path.basename(latest.rstrip('/'))\n    steps_file = os.path.join(latest, 'monitor_steps.json')\n    if os.path.exists(steps_file):\n        with open(steps_file) as f:\n            steps = json.load(f)\n        if steps:\n            last = steps[-1]\n            print(f'\\n=== LIVE MONITOR: {name} (step {last.get(\"step\", \"?\")}) ===')\n            print(f'  Loss: {last.get(\"loss\", \"?\"):.4f}')\n            print(f'  LR:   {last.get(\"lr\", \"?\"):.6f}')\n            print(f'  Total steps recorded: {len(steps)}')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "visualize_monitor"
   },
   "source": [
    "# Cell 6: Visualize physics diagnostics (12-panel dashboard per variant)\n",
    "# Run after each variant completes, or at the end for all variants\n",
    "import glob, os\n",
    "\n",
    "DRIVE_DIR = '/content/drive/MyDrive/wavellm_results'\n",
    "monitor_dirs = sorted(glob.glob(f'{DRIVE_DIR}/monitor/*/'))\n",
    "\n",
    "if not monitor_dirs:\n",
    "    print('No monitor data yet. Run Cell 4 first.')\n",
    "else:\n",
    "    print(f'Found {len(monitor_dirs)} monitored variants:')\n",
    "    for mdir in monitor_dirs:\n",
    "        snap_file = os.path.join(mdir, 'monitor_snapshots.json')\n",
    "        step_file = os.path.join(mdir, 'monitor_steps.json')\n",
    "        if os.path.exists(snap_file):\n",
    "            name = os.path.basename(mdir.rstrip('/'))\n",
    "            print(f'\\n=== Generating dashboard: {name} ===')\n",
    "            cmd = f'python diagnostics/visualize_monitor.py {snap_file}'\n",
    "            if os.path.exists(step_file):\n",
    "                cmd += f' {step_file}'\n",
    "            !{cmd}\n",
    "            # Display dashboard inline\n",
    "            png = snap_file.replace('.json', '_dashboard.png')\n",
    "            if os.path.exists(png):\n",
    "                from IPython.display import Image, display\n",
    "                display(Image(filename=png, width=1200))\n",
    "            else:\n",
    "                print(f'  Dashboard PNG not found at {png}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "final_results"
   },
   "source": "# Cell 7: Final results table + gap analysis (merges per-variant files)\nimport json, os\n\nDRIVE_DIR = '/content/drive/MyDrive/wavellm_results'\n\n# Collect results from all sources: per-variant files, partial JSON, final JSON\nall_variants = ['A_v433_baseline', 'B_normalized_exp_only', 'C_gate_10x_only',\n                'D_kernel_reach_only', 'E_v434_full', 'F_standard']\nresults = []\ndone = set()\n\n# Per-variant result files (parallel mode)\nfor key in all_variants:\n    vpath = os.path.join(DRIVE_DIR, f'v434_ablation_{key}.json')\n    if os.path.exists(vpath):\n        with open(vpath) as f:\n            r = json.load(f)\n        results.append(r)\n        done.add(key)\n\n# Partial JSON fallback (sequential mode)\npartial_path = os.path.join(DRIVE_DIR, 'v434_ablation_partial.json')\nif os.path.exists(partial_path):\n    with open(partial_path) as f:\n        data = json.load(f)\n    for r in data.get('results', []):\n        abl = r.get('ablation')\n        if abl and abl not in done:\n            results.append(r)\n            done.add(abl)\n\n# Final JSON fallback\nfinal_path = os.path.join(DRIVE_DIR, 'v434_ablation.json')\nif os.path.exists(final_path):\n    with open(final_path) as f:\n        data = json.load(f)\n    for r in data.get('results', []):\n        abl = r.get('ablation')\n        if abl and abl not in done:\n            results.append(r)\n            done.add(abl)\n\nif not results:\n    print('No results found. Run Cell 4 first.')\nelse:\n    remaining = [v for v in all_variants if v not in done]\n    status = 'FINAL' if not remaining else f'PARTIAL ({len(done)}/{len(all_variants)})'\n\n    print(f'{\"=\"*60}')\n    print(f'  V4.3.4 ABLATION RESULTS ({status})')\n    print(f'{\"=\"*60}')\n    print(f'\\n  {\"Variant\":<30} {\"PPL\":>8} {\"Acc\":>7} {\"Params\":>12} {\"tok/s\":>10}')\n    print(f'  {\"-\"*30} {\"-\"*8} {\"-\"*7} {\"-\"*12} {\"-\"*10}')\n\n    std_ppl = None\n    for r in results:\n        name = r.get('ablation_name', r.get('run_name', '?'))\n        ppl = r.get('best_ppl', 'N/A')\n        acc = r.get('best_acc', 'N/A')\n        params = r.get('params', 'N/A')\n        tps = r.get('tokens_per_sec', 'N/A')\n        ppl_s = f'{ppl:>8.1f}' if isinstance(ppl, (int,float)) else f'{ppl:>8}'\n        acc_s = f'{acc:>6.1f}%' if isinstance(acc, (int,float)) else f'{acc:>7}'\n        params_s = f'{params:>12,}' if isinstance(params, (int,float)) else f'{params:>12}'\n        tps_s = f'{tps:>10,}' if isinstance(tps, (int,float)) else f'{tps:>10}'\n        print(f'  {name:<30} {ppl_s} {acc_s} {params_s} {tps_s}')\n        if r.get('ablation') == 'F_standard' and isinstance(ppl, (int,float)):\n            std_ppl = ppl\n\n    # Gap analysis\n    if std_ppl:\n        print(f'\\n  --- GAP ANALYSIS (vs Standard PPL {std_ppl:.1f}) ---')\n        print(f'  {\"Variant\":<30} {\"PPL\":>8} {\"Gap\":>8} {\"Delta\":>8}')\n        print(f'  {\"-\"*30} {\"-\"*8} {\"-\"*8} {\"-\"*8}')\n        baseline_ppl = None\n        for r in results:\n            ppl = r.get('best_ppl')\n            if not isinstance(ppl, (int, float)):\n                continue\n            name = r.get('ablation_name', r.get('run_name', '?'))\n            gap = ppl / std_ppl\n            if r.get('ablation') == 'A_v433_baseline':\n                baseline_ppl = ppl\n            delta = f'{((ppl - baseline_ppl) / baseline_ppl * 100):>+7.1f}%' if baseline_ppl else '    base'\n            print(f'  {name:<30} {ppl:>8.1f} {gap:>7.2f}x {delta}')\n\n    # Save merged final results if all done\n    if not remaining:\n        merged = {\n            'metadata': {\n                'benchmark': 'v434_ablation',\n                'scale': 'S1',\n                'timestamp': __import__('time').strftime('%Y-%m-%d %H:%M:%S'),\n            },\n            'results': results,\n        }\n        merged_path = os.path.join(DRIVE_DIR, 'v434_ablation.json')\n        with open(merged_path, 'w') as f:\n            json.dump(merged, f, indent=2)\n        print(f'\\n  Merged results saved: {merged_path}')",
   "execution_count": null,
   "outputs": []
  }
 ]
}