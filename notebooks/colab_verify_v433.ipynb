{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Wave Field LLM — V4.3.3 Benchmark Verification\n",
    "\n",
    "Reproduces the S1 result: **SPECTRE-Wave PPL 239 vs Standard PPL 171**\n",
    "\n",
    "Runtime: ~20-25 min on T4, ~12 min on A100"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Cell 1: Setup — pin to V4.3.3 commit (NOT V4.3.4 which regresses!)\n!git clone https://github.com/Pankh-AI/wave-field-llm.git\n%cd wave-field-llm\n!git checkout 51e7015   # V4.3.3 exactly — V4.3.4 has untested NormalizedExp/damping changes\n!pip install -q tokenizers datasets",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 2: Check GPU\n",
    "import torch\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name()}')\n",
    "    print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "else:\n",
    "    raise RuntimeError('No GPU! Go to Runtime > Change runtime type > T4 GPU')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 3: Run V4.3.3 SPECTRE-Wave only (~20 min on T4, ~10 min on A100)\nimport os\nos.environ['MODEL'] = 'wave'            # Wave only — Standard PPL 171 already verified\nos.environ['MONITOR'] = '0'             # Skip monitor for speed\nos.environ['BATCH_SIZE'] = '16'\n\n!python benchmarks/benchmark_scaling.py",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 5: Compare results\n",
    "import json\n",
    "\n",
    "with open('results/scaling_s1.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print('=' * 60)\n",
    "print('  RESULTS')\n",
    "print('=' * 60)\n",
    "for r in data['results']:\n",
    "    print(f\"\\n  {r['run_name']}\")\n",
    "    print(f\"    PPL:    {r['best_ppl']:.2f}\")\n",
    "    print(f\"    Acc:    {r['best_acc']:.2f}%\")\n",
    "    print(f\"    Params: {r['params']:,}\")\n",
    "    print(f\"    Speed:  {r['tokens_per_sec']:,} tok/s\")\n",
    "    print(f\"    Time:   {r['total_time_s']:.0f}s\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}