{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Wave Field LLM — S3 Benchmark (100M params, 100M tokens)\n",
        "\n",
        "**V4.3.7 SPECTRE-Wave** at S3 scale on Colab T4 (16GB).\n",
        "\n",
        "| Scale | Params | Tokens | Dataset | embed/layers/heads | T4 time |\n",
        "|-------|--------|--------|---------|-------------------|---------|\n",
        "| S1 | 22M | 20M | WikiText-2 | 384/8/8 | ~25 min |\n",
        "| S2 | 55M | 50M | WikiText-103 | 512/12/8 | ~2.5 hrs |\n",
        "| **S3** | **100M** | **100M** | **WikiText-103** | **768/12/12** | **~3-4 hrs** |\n",
        "\n",
        "**Strategy for free tier:**\n",
        "- Checkpoints saved to **Google Drive** (survives disconnects)\n",
        "- Auto-resume from last checkpoint on reconnect\n",
        "- Wave model only (skip Standard to save time)\n",
        "- Gradient checkpointing + fp16 AMP (T4 optimized)\n",
        "- Eval every 5M tokens (~20 checkpoints total)\n",
        "\n",
        "**If disconnected:** Just re-run all cells. It will auto-resume from the last checkpoint on Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 1: Mount Google Drive for persistent checkpoints\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create persistent directory\n",
        "import os\n",
        "DRIVE_DIR = '/content/drive/MyDrive/wave-field-llm'\n",
        "CKPT_DIR = os.path.join(DRIVE_DIR, 'checkpoints')\n",
        "CACHE_DIR = os.path.join(DRIVE_DIR, 'cache')\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "print(f'Drive checkpoint dir: {CKPT_DIR}')\n",
        "print(f'Existing files: {os.listdir(CKPT_DIR) if os.path.exists(CKPT_DIR) else []}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 2: Clone repo + install deps\n",
        "!git clone https://github.com/Pankh-AI/wave-field-llm.git 2>/dev/null || (cd wave-field-llm && git pull)\n",
        "%cd wave-field-llm\n",
        "!pip install -q tokenizers datasets\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "from src import __version__\n",
        "print(f'\\nCode version: V{__version__}')\n",
        "assert __version__ >= '4.3.7', f'Need V4.3.7+, got {__version__}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 3: GPU check + VRAM estimation\n",
        "import torch\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'CUDA: {torch.cuda.is_available()}')\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    raise RuntimeError('No GPU! Go to Runtime > Change runtime type > T4 GPU')\n",
        "\n",
        "gpu_name = torch.cuda.get_device_name()\n",
        "vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "print(f'GPU: {gpu_name}')\n",
        "print(f'VRAM: {vram_gb:.1f} GB')\n",
        "\n",
        "# S3 VRAM: ~100M model (400MB) + AdamW (1.2GB) + activations w/ checkpointing (~3GB)\n",
        "# Total ~5-6GB. T4 (16GB) has plenty.\n",
        "if vram_gb < 12:\n",
        "    print(f'WARNING: Only {vram_gb:.1f} GB VRAM. S3 needs ~6GB. Might be tight.')\n",
        "else:\n",
        "    print(f'VRAM OK: {vram_gb:.1f} GB (S3 needs ~6GB)')\n",
        "\n",
        "# T4 doesn't support bf16 well — we'll use fp16\n",
        "if 'T4' in gpu_name:\n",
        "    print('\\nT4 detected: Using fp16 AMP + GradScaler')\n",
        "    print('Estimated time: ~3-4 hours (Wave only)')\n",
        "elif 'A100' in gpu_name:\n",
        "    print('\\nA100 detected: Will use bf16 AMP (no GradScaler needed)')\n",
        "    print('Estimated time: ~1.5-2 hours (Wave only)')\n",
        "else:\n",
        "    print(f'\\nGPU: {gpu_name}. Estimated ~3-5 hours.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 4: Symlink Drive dirs so benchmark_scaling.py saves there\n",
        "import os, shutil\n",
        "\n",
        "# Symlink results/checkpoints → Drive\n",
        "local_ckpt = 'results/checkpoints'\n",
        "os.makedirs('results', exist_ok=True)\n",
        "if os.path.islink(local_ckpt):\n",
        "    os.unlink(local_ckpt)\n",
        "elif os.path.isdir(local_ckpt):\n",
        "    # Move any existing checkpoints to Drive first\n",
        "    for f in os.listdir(local_ckpt):\n",
        "        src = os.path.join(local_ckpt, f)\n",
        "        dst = os.path.join(CKPT_DIR, f)\n",
        "        if not os.path.exists(dst):\n",
        "            shutil.move(src, dst)\n",
        "    shutil.rmtree(local_ckpt)\n",
        "os.symlink(CKPT_DIR, local_ckpt)\n",
        "print(f'Checkpoints symlinked: {local_ckpt} -> {CKPT_DIR}')\n",
        "\n",
        "# Symlink results/cache → Drive (tokenizer + token arrays, ~500MB)\n",
        "local_cache = 'results/cache'\n",
        "if os.path.islink(local_cache):\n",
        "    os.unlink(local_cache)\n",
        "elif os.path.isdir(local_cache):\n",
        "    for f in os.listdir(local_cache):\n",
        "        src = os.path.join(local_cache, f)\n",
        "        dst = os.path.join(CACHE_DIR, f)\n",
        "        if not os.path.exists(dst):\n",
        "            shutil.move(src, dst)\n",
        "    shutil.rmtree(local_cache)\n",
        "os.symlink(CACHE_DIR, local_cache)\n",
        "print(f'Cache symlinked: {local_cache} -> {CACHE_DIR}')\n",
        "\n",
        "# Create other results dirs locally (non-critical, don't need persistence)\n",
        "os.makedirs('results/data', exist_ok=True)\n",
        "os.makedirs('results/plots', exist_ok=True)\n",
        "os.makedirs('results/monitor', exist_ok=True)\n",
        "\n",
        "print(f'\\nDrive checkpoint files: {os.listdir(CKPT_DIR)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 5: Run S3 benchmark (Wave only)\n",
        "#\n",
        "# If disconnected: re-run all cells. RESUME=1 auto-detects the\n",
        "# checkpoint on Drive and continues from where it left off.\n",
        "#\n",
        "import os\n",
        "os.environ['SCALE'] = 'S3'              # S3: 100M params, 100M tokens\n",
        "os.environ['MODEL'] = 'wave'            # Wave only (skip Standard, save ~3hrs)\n",
        "os.environ['DATASET'] = '103'           # WikiText-103 (133M tokens, 1 epoch)\n",
        "os.environ['RESUME'] = '1'              # Auto-resume from Drive checkpoint\n",
        "os.environ['MONITOR'] = '1'             # Keep monitor on for diagnostics\n",
        "# os.environ['BATCH_SIZE'] = '6'        # Uncomment if OOM (unlikely on T4 16GB)\n",
        "\n",
        "!python benchmarks/benchmark_scaling.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 6: Results analysis\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Try to load results\n",
        "results_path = 'results/data/scaling_s3.json'\n",
        "if not os.path.exists(results_path):\n",
        "    # Fall back to generic file\n",
        "    results_path = 'results/data/scaling_benchmark.json'\n",
        "\n",
        "if os.path.exists(results_path):\n",
        "    with open(results_path) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    print('=' * 65)\n",
        "    print('  S3 BENCHMARK RESULTS (100M params, 100M tokens)')\n",
        "    print(f'  Dataset: {data[\"metadata\"].get(\"dataset\", \"unknown\")}')\n",
        "    print(f'  GPU: {data[\"metadata\"].get(\"gpu\", \"unknown\")}')\n",
        "    print('=' * 65)\n",
        "\n",
        "    for r in data['results']:\n",
        "        print(f\"\\n  {r['run_name']}\")\n",
        "        print(f\"    PPL:    {r['best_ppl']:.2f}\")\n",
        "        print(f\"    Acc:    {r['best_acc']:.2f}%\")\n",
        "        print(f\"    Params: {r['params']:,}\")\n",
        "        print(f\"    Speed:  {r['tokens_per_sec']:,} tok/s\")\n",
        "        print(f\"    Time:   {r['total_time_s']:.0f}s ({r['total_time_s']/60:.0f} min)\")\n",
        "        print(f\"    Epochs: {r.get('epochs', '?')}\")\n",
        "\n",
        "        # Print training curve highlights\n",
        "        curve = r.get('curve', [])\n",
        "        if curve:\n",
        "            print(f\"\\n    Training curve ({len(curve)} checkpoints):\")\n",
        "            print(f\"    {'Tokens':>10} {'PPL':>10} {'Acc':>8}\")\n",
        "            for pt in curve:\n",
        "                print(f\"    {pt['tokens_M']:>8.1f}M {pt['ppl']:>10.2f} {pt['acc']:>7.1f}%\")\n",
        "else:\n",
        "    print('No results file found yet.')\n",
        "    print('If training was interrupted, check checkpoint status:')\n",
        "    ckpt_path = os.path.join(CKPT_DIR, 'spectre-wave_s3_resume.pt')\n",
        "    if os.path.exists(ckpt_path):\n",
        "        import torch\n",
        "        ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
        "        print(f'\\n  Checkpoint found on Drive!')\n",
        "        print(f'  Step: {ckpt[\"step\"]} / ~16,276')\n",
        "        print(f'  Tokens: {ckpt[\"tokens_seen\"]/1e6:.1f}M / 100M')\n",
        "        print(f'  Best PPL: {ckpt[\"best_ppl\"]:.2f}')\n",
        "        print(f'  Best Acc: {ckpt[\"best_acc\"]:.2f}%')\n",
        "        print(f'  Progress: {ckpt[\"tokens_seen\"]/100e6*100:.1f}%')\n",
        "        print(f'\\n  Re-run Cell 5 to continue training from this checkpoint.')\n",
        "    else:\n",
        "        print(f'  No checkpoint on Drive either. Training may not have started.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 7: Run causality test on trained S3 model\n",
        "!python tests/test_causality.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 8: Run verification suite on S3 checkpoint\n",
        "# (Only run this after training completes or has enough checkpoints)\n",
        "import os\n",
        "ckpt_path = os.path.join(CKPT_DIR, 'spectre-wave_s3.pt')\n",
        "if os.path.exists(ckpt_path):\n",
        "    !python tests/verify_results.py --scale S3 --dataset 103 --skip-generation\n",
        "else:\n",
        "    print('No S3 checkpoint yet. Run Cell 5 first.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 9: Copy results to Drive (in case session dies before download)\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "DRIVE_RESULTS = os.path.join(DRIVE_DIR, 'results_s3')\n",
        "os.makedirs(DRIVE_RESULTS, exist_ok=True)\n",
        "\n",
        "# Copy data files\n",
        "for f in ['scaling_s3.json', 'scaling_benchmark.json', 'verification_s3.json']:\n",
        "    src = os.path.join('results/data', f)\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy2(src, DRIVE_RESULTS)\n",
        "        print(f'Copied: {f}')\n",
        "\n",
        "# Copy monitor data\n",
        "mon_dir = 'results/monitor/spectre-wave_s3'\n",
        "if os.path.isdir(mon_dir):\n",
        "    dst = os.path.join(DRIVE_RESULTS, 'monitor')\n",
        "    if os.path.exists(dst):\n",
        "        shutil.rmtree(dst)\n",
        "    shutil.copytree(mon_dir, dst)\n",
        "    print('Copied: monitor data')\n",
        "\n",
        "print(f'\\nAll results saved to: {DRIVE_RESULTS}')\n",
        "print(f'Files: {os.listdir(DRIVE_RESULTS)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 10: Download results locally (optional)\n",
        "from google.colab import files\n",
        "\n",
        "for f in ['results/data/scaling_s3.json', 'results/data/verification_s3.json']:\n",
        "    if os.path.exists(f):\n",
        "        files.download(f)\n",
        "        print(f'Downloaded: {f}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
